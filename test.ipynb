{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from dataclasses import dataclass\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class ASRconfig:\n",
    "    sample_rate: int = 16000\n",
    "    n_fft: int = 400\n",
    "    win_length: int = 400\n",
    "    hop_length: int = 160\n",
    "    n_mels: int = 80\n",
    "    center: bool = True\n",
    "    time_mask_param: int = 30\n",
    "    freq_mask_param: int = 15\n",
    "    model_dim: int = 256\n",
    "    feedforward_dim: int = 1024\n",
    "    dropout: float = 0.1\n",
    "    num_heads: int = 4\n",
    "    num_layers: int = 6\n",
    "    encoder_normalize_first: bool = True\n",
    "    max_len: int = 5000\n",
    "    vocab_size: int = 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AudioFeatureExtractor(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.MelSpec = T.MelSpectrogram(\n",
    "            sample_rate=config.sample_rate,\n",
    "            n_fft=config.n_fft,\n",
    "            win_length=config.win_length,\n",
    "            hop_length=config.hop_length,\n",
    "            n_mels=config.n_mels,\n",
    "            normalized=False,\n",
    "            center=config.center\n",
    "        )\n",
    "        self.log = lambda x: torch.log1p(x)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        \n",
    "        print(\"zeros in speech signal : \")\n",
    "        print([(u==0).sum() for u in x])\n",
    "        x = self.MelSpec(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        if self.config.center:\n",
    "            frame_lengths = 1 + lengths // self.config.hop_length\n",
    "        else:\n",
    "            frame_lengths = 1 + (lengths - self.config.win_length) // self.config.hop_length\n",
    "\n",
    "        print(\"frame lengths : \", frame_lengths)\n",
    "        max_len = x.size(1)\n",
    "        range_ = torch.arange(max_len, device=x.device)\n",
    "        mask = range_[None, :] <= frame_lengths[:, None]\n",
    "        print(mask)\n",
    "        mask = mask.unsqueeze(-1)\n",
    "        \n",
    "        x = torch.where(mask, x, torch.zeros_like(x))\n",
    "        for i, utt in enumerate(x):\n",
    "            print(\"utterance : \", i)\n",
    "            print(utt)\n",
    "            print(utt.shape)\n",
    "            print(lengths[i])\n",
    "            print(frame_lengths[i])\n",
    "            print(\"number of zero frames : \", (utt==0).all(dim=1).sum().item())\n",
    "            print(\"number of zero features : \", (utt==0).all(dim=0).sum().item())\n",
    "            arr = utt.numpy()\n",
    "            np.savetxt(f\"{i}_utterance_mel.txt\", arr)\n",
    "\n",
    "        print(\"zeros in MelSpec : \")\n",
    "        print([(u==0).sum() for u in x])\n",
    "        x = self.log(x)\n",
    "        print(\"zeros in MelSpec after log : \")\n",
    "        print([(u==0).sum() for u in x])\n",
    "        return x, frame_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UtteranceMVN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        normalized_x = []        \n",
    "        for utt, l in zip(x, lengths):\n",
    "            print(utt.shape)\n",
    "            print(utt)\n",
    "            mean = utt[:l, :].mean(dim=0, keepdims=True)\n",
    "            std = utt[:l, :].std(dim=0, keepdims=True)\n",
    "            print(\"std shape : \", std.shape)\n",
    "            print(\"std : \", std)\n",
    "            print(\"zeros in std : \", (std == 0).sum())\n",
    "            utt[:l, :] = (utt[:l, :] - mean) / std\n",
    "            normalized_x.append(utt)\n",
    "        \n",
    "        normalized_x = torch.stack(normalized_x)\n",
    "        return normalized_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros in speech signal : \n",
      "[tensor(4000), tensor(8000)]\n",
      "frame lengths :  tensor([101,  51])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False]])\n",
      "utterance :  0\n",
      "tensor([[  18.6247,   67.4226,   37.2385,  ...,  300.5623,  972.3760,\n",
      "         2582.6804],\n",
      "        [  44.2114,  160.0482,   94.7193,  ...,  947.3735, 1405.3047,\n",
      "         1026.0333],\n",
      "        [  22.8586,   82.7496,   92.2339,  ..., 1068.0688, 1274.7822,\n",
      "          367.8439],\n",
      "        ...,\n",
      "        [   4.7629,   17.2421,   23.6407,  ...,  543.6440,  258.0369,\n",
      "          651.6619],\n",
      "        [   6.0333,   21.8409,    9.5500,  ...,  418.2242,  472.7133,\n",
      "          357.2845],\n",
      "        [  12.9861,   47.0104,   20.3999,  ...,  438.6854,  851.1222,\n",
      "          928.5728]])\n",
      "torch.Size([101, 80])\n",
      "tensor(16000)\n",
      "tensor(101)\n",
      "number of zero frames :  22\n",
      "number of zero features :  0\n",
      "utterance :  1\n",
      "tensor([[ 13.2221,  47.8649,   4.5875,  ..., 490.7378, 840.3808, 629.8474],\n",
      "        [ 15.9469,  57.7287,  55.4713,  ..., 491.7243, 564.6500, 814.4913],\n",
      "        [ 66.0394, 239.0672,  60.7368,  ..., 393.7557, 698.1182, 722.9800],\n",
      "        ...,\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]])\n",
      "torch.Size([101, 80])\n",
      "tensor(8000)\n",
      "tensor(51)\n",
      "number of zero frames :  49\n",
      "number of zero features :  0\n",
      "zeros in MelSpec : \n",
      "[tensor(1760), tensor(3920)]\n",
      "zeros in MelSpec after log : \n",
      "[tensor(1760), tensor(3920)]\n",
      "torch.Size([101, 80])\n",
      "tensor([[2.9768, 4.2257, 3.6438,  ..., 5.7090, 6.8808, 7.8570],\n",
      "        [3.8113, 5.0817, 4.5614,  ..., 6.8547, 7.2487, 6.9344],\n",
      "        [3.1721, 4.4278, 4.5351,  ..., 6.9745, 7.1513, 5.9104],\n",
      "        ...,\n",
      "        [1.7514, 2.9037, 3.2044,  ..., 6.3001, 5.5570, 6.4811],\n",
      "        [1.9507, 3.1286, 2.3561,  ..., 6.0384, 6.1606, 5.8813],\n",
      "        [2.6381, 3.8714, 3.0634,  ..., 6.0861, 6.7477, 6.8347]])\n",
      "std shape :  torch.Size([1, 80])\n",
      "std :  tensor([[1.5829, 2.0763, 1.9414, 1.9038, 2.1160, 1.8440, 1.9988, 2.1566, 1.9983,\n",
      "         2.0330, 2.1918, 2.1074, 1.9769, 2.0638, 2.1252, 2.1304, 2.1172, 2.1821,\n",
      "         2.2087, 2.2152, 2.1324, 2.1277, 2.1806, 2.2393, 2.1743, 2.0989, 2.1700,\n",
      "         2.0863, 2.1831, 2.3284, 2.2440, 2.3516, 2.2547, 2.3143, 2.3464, 2.4100,\n",
      "         2.3720, 2.3617, 2.3277, 2.3807, 2.4272, 2.4304, 2.4845, 2.4638, 2.4697,\n",
      "         2.5014, 2.5440, 2.5565, 2.4873, 2.5016, 2.5331, 2.5138, 2.5514, 2.5230,\n",
      "         2.5147, 2.5429, 2.5468, 2.5786, 2.5593, 2.6110, 2.6123, 2.6390, 2.6673,\n",
      "         2.6974, 2.6929, 2.7456, 2.7576, 2.7296, 2.7590, 2.7662, 2.7770, 2.8101,\n",
      "         2.8326, 2.8144, 2.8437, 2.8605, 2.8531, 2.8498, 2.9126, 2.9289]])\n",
      "zeros in std :  tensor(0)\n",
      "torch.Size([101, 80])\n",
      "tensor([[2.6548, 3.8891, 1.7205,  ..., 6.1979, 6.7350, 6.4471],\n",
      "        [2.8301, 4.0729, 4.0337,  ..., 6.1999, 6.3380, 6.7038],\n",
      "        [4.2053, 5.4809, 4.1229,  ..., 5.9783, 6.5498, 6.5848],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "std shape :  torch.Size([1, 80])\n",
      "std :  tensor([[1.0906, 1.2207, 1.1272, 1.1206, 1.3597, 1.0918, 1.3201, 1.4002, 1.0741,\n",
      "         0.8978, 0.9754, 1.2363, 0.9303, 0.8484, 0.8294, 0.8817, 0.8855, 0.9730,\n",
      "         1.0606, 1.1470, 1.0626, 1.0074, 1.0145, 0.8483, 0.9285, 0.7901, 0.7916,\n",
      "         1.0263, 1.0382, 1.0045, 1.0624, 0.9686, 0.8274, 0.6415, 0.9470, 0.8784,\n",
      "         0.8183, 0.6151, 0.6967, 0.6703, 0.7069, 0.6188, 0.7449, 0.7768, 0.8814,\n",
      "         0.7118, 0.6122, 0.6539, 0.7055, 0.7601, 0.6268, 0.7590, 0.6161, 0.6442,\n",
      "         0.6637, 0.5990, 0.6578, 0.7544, 0.6614, 0.5824, 0.5849, 0.6093, 0.5462,\n",
      "         0.5398, 0.6250, 0.5868, 0.5588, 0.5244, 0.5649, 0.6274, 0.5584, 0.5657,\n",
      "         0.5894, 0.5984, 0.4881, 0.3895, 0.4239, 0.5356, 0.4569, 0.4102]])\n",
      "zeros in std :  tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = ASRconfig()\n",
    "extractor = AudioFeatureExtractor(config)\n",
    "normalizer = UtteranceMVN(config)\n",
    "input1 = torch.cat([torch.randn(8000), torch.zeros(4000), torch.randn(4000)])\n",
    "# print(input1.shape)\n",
    "input2 = torch.randn(8000)\n",
    "input = [input1, input2]\n",
    "input = torch.nn.utils.rnn.pad_sequence(input, batch_first=True, padding_value=0.0)\n",
    "out, out_frame_lengths = extractor(input, torch.tensor([16000, 8000]))\n",
    "\n",
    "out = normalizer(out, out_frame_lengths)\n",
    "# print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icefall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
